{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c480282",
   "metadata": {},
   "source": [
    "# HMMER Profile Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89cfbe7-5222-40d2-ae02-d40d41687c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG: build HMMs directly from filtered folders in DIRS ===\n",
    "from pathlib import Path\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "import pandas as pd, numpy as np\n",
    "import collections, random, re, os, shutil, subprocess, shlex\n",
    "import contextlib, io\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Paths\n",
    "BASE        = Path(\"/~/HMM-PROFILES-FOR-CA-ENZYMES\")\n",
    "REBASE      = BASE / \"OUTPUT\"\n",
    "LOGS        = REBASE / \"logs\";                  LOGS.mkdir(parents=True, exist_ok=True)\n",
    "TMP         = REBASE / \"tmp\";                   TMP.mkdir(parents=True, exist_ok=True)\n",
    "ALIGN_DIR   = REBASE / \"per_class_aligned\";     ALIGN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SPLIT_DIR   = REBASE / \"per_class_split\";       SPLIT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TRAIN_ALN   = REBASE / \"train_aligned\";         TRAIN_ALN.mkdir(parents=True, exist_ok=True)\n",
    "CLEAN_ALN   = REBASE / \"train_aligned_clean\";   CLEAN_ALN.mkdir(parents=True, exist_ok=True)\n",
    "TRIM_ALN    = REBASE / \"train_aligned_trimmed\"; TRIM_ALN.mkdir(parents=True, exist_ok=True)\n",
    "PROFILES    = REBASE / \"profiles\";              PROFILES.mkdir(parents=True, exist_ok=True)\n",
    "HMM_LIB     = REBASE / \"hmmer_lib\";             HMM_LIB.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS     = REBASE / \"results\";               RESULTS.mkdir(parents=True, exist_ok=True)\n",
    "OUT     = REBASE / \"clustalo_consensus_classify\"\n",
    "\n",
    "# filtered sets (edit as needed)\n",
    "DIRS = [\n",
    "    REBASE / \"filtered_sets_per_class\" / \"alpha_no_change\",\n",
    "    REBASE / \"filtered_sets_per_class\" / \"beta_no_change\",\n",
    "    REBASE / \"filtered_sets_per_class\" / \"gamma_no_change\",\n",
    "    REBASE / \"filtered_sets_per_class\" / \"delta_250_600\",\n",
    "    REBASE / \"filtered_sets_per_class\" / \"zeta_150_250\",\n",
    "    REBASE / \"filtered_sets_per_class\" / \"eta_300_no_max\",\n",
    "    REBASE / \"filtered_sets_per_class\" / \"theta_250_550\",\n",
    "    REBASE / \"filtered_sets_per_class\" / \"iota_no_change\",\n",
    "]\n",
    "\n",
    "# RNG for train/test split\n",
    "RNG_SEED = 42\n",
    "random.seed(RNG_SEED)\n",
    "\n",
    "def first_token(s: str) -> str:\n",
    "    return (s or \"\").split()[0]\n",
    "\n",
    "def write_fasta(records, path: Path):\n",
    "    if records:\n",
    "        SeqIO.write(records, str(path), \"fasta\")\n",
    "\n",
    "# 0) Collect sequences per class from DIRS (merge & dedup by ID)\n",
    "class_to_records = {}  # { \"8ca.alpha.45\": {id: SeqRecord, ...}, ... }\n",
    "for d in DIRS:\n",
    "    assert d.exists(), f\"Missing folder: {d}\"\n",
    "    for ext in (\"*.txt\",\"*.fa\",\"*.fasta\",\"*.faa\",\"*.fas\"):\n",
    "        for f in d.glob(ext):\n",
    "            cls = f.stem\n",
    "            bucket = class_to_records.setdefault(cls, {})\n",
    "            for r in SeqIO.parse(str(f), \"fasta\"):\n",
    "                rid = first_token(r.id or r.description)\n",
    "                if rid not in bucket:\n",
    "                    bucket[rid] = SeqRecord(Seq(str(r.seq)), id=rid, description=\"\")\n",
    "\n",
    "FILTERED_UPDATED_FASTAS = REBASE / \"OG_from_DIRS\"; FILTERED_UPDATED_FASTAS.mkdir(parents=True, exist_ok=True)\n",
    "for cls, id2rec in class_to_records.items():\n",
    "    out = FILTERED_UPDATED_FASTAS / f\"{cls}.txt\"\n",
    "    write_fasta(list(id2rec.values()), out)\n",
    "\n",
    "print(f\"[OK] Wrote per-class merged FASTAs to: {FILTERED_UPDATED_FASTAS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0411b76-6bc2-4caa-90fe-e5096110b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure Clustal omega  exists\n",
    "clo = shutil.which(\"clustalo\") or shutil.which(os.environ.get(\"CLUSTALO_BIN\",\"\"))\n",
    "assert (clo), \"Install clustalo in your env.\"\n",
    "\n",
    "def run(cmd, log=None, check=False):\n",
    "    print(\"$\", cmd)\n",
    "    p = subprocess.run(shlex.split(cmd), capture_output=True, text=True)\n",
    "    if log:\n",
    "        Path(log).write_text(p.stdout + \"\\n--- STDERR ---\\n\" + p.stderr)\n",
    "    if check and p.returncode != 0:\n",
    "        raise RuntimeError(f\"Command failed ({p.returncode})\\n{p.stderr}\")\n",
    "    return p\n",
    "\n",
    "# 1) Build combined unaligned FASTA & run global MSA\n",
    "combined_unaln = TMP / \"all_classes_DIRS.raw.faa\"\n",
    "seen = set()\n",
    "with open(combined_unaln, \"w\") as outfa:\n",
    "    for f in sorted(FILTERED_UPDATED_FASTAS.glob(\"*.txt\")):\n",
    "        for r in SeqIO.parse(str(f), \"fasta\"):\n",
    "            sid = first_token(r.id or r.description)\n",
    "            if sid in seen: continue\n",
    "            seen.add(sid)\n",
    "            r.id = sid; r.description = \"\"\n",
    "            SeqIO.write(r, outfa, \"fasta\")\n",
    "print(f\"[combine] total unique sequences: {len(seen)}\")\n",
    "\n",
    "NEW_MSA = REBASE / \"all_classes_DIRS.aln.fasta\"\n",
    "if clo:\n",
    "    run(f'clustalo -i \"{combined_unaln}\" -o \"{NEW_MSA}\" --force --threads=4 --seqtype=Protein', \n",
    "        log=str(LOGS / \"clustalo_DIRS.log\"), check=True)\n",
    "\n",
    "print(\"[OK] Global MSA:\", NEW_MSA)\n",
    "\n",
    "# 2) Slice per-class from global MSA\n",
    "msa_records = list(SeqIO.parse(str(NEW_MSA), \"fasta\"))\n",
    "msa_index   = { first_token(r.id or r.description): r for r in msa_records }\n",
    "rows = []\n",
    "for f in sorted(FILTERED_UPDATED_FASTAS.glob(\"*.txt\")):\n",
    "    cls = f.stem\n",
    "    want_ids = [ first_token(r.id or r.description) for r in SeqIO.parse(str(f), \"fasta\") ]\n",
    "    found = []\n",
    "    for i in want_ids:\n",
    "        if i in msa_index:\n",
    "            r = msa_index[i]\n",
    "            found.append(SeqRecord(Seq(str(r.seq)), id=i, description=\"\"))\n",
    "    out_aln = ALIGN_DIR / f\"{cls}.aln.fasta\"\n",
    "    if found:\n",
    "        SeqIO.write(found, str(out_aln), \"fasta\")\n",
    "    rows.append({\"class\": cls, \"wanted\": len(want_ids), \"found\": len(found), \"out\": str(out_aln)})\n",
    "\n",
    "slice_report = pd.DataFrame(rows).sort_values(\"class\")\n",
    "display(slice_report)\n",
    "slice_report.to_csv(REBASE / \"01_DIRS_slice_report.csv\", index=False)\n",
    "\n",
    "# 3) Train/Test split (80/20 stratified by class)\n",
    "split_rows = []\n",
    "for f in sorted(FILTERED_UPDATED_FASTAS.glob(\"*.txt\")):\n",
    "    cls = f.stem\n",
    "    ids = sorted({ first_token(r.id or r.description) for r in SeqIO.parse(str(f), \"fasta\") })\n",
    "    if len(ids) < 3:\n",
    "        (SPLIT_DIR / f\"{cls}.train.ids\").write_text(\"\\n\".join(ids) + (\"\\n\" if ids else \"\"))\n",
    "        (SPLIT_DIR / f\"{cls}.test.ids\").write_text(\"\")\n",
    "        split_rows.append({\"class\":cls,\"n_total\":len(ids),\"n_train\":len(ids),\"n_test\":0,\"note\":\"too_small\"})\n",
    "        continue\n",
    "    n_train = max(2, int(0.8 * len(ids)))\n",
    "    random.shuffle(ids)\n",
    "    train_ids, test_ids = sorted(ids[:n_train]), sorted(ids[n_train:])\n",
    "    (SPLIT_DIR / f\"{cls}.train.ids\").write_text(\"\\n\".join(train_ids) + \"\\n\")\n",
    "    (SPLIT_DIR / f\"{cls}.test.ids\").write_text(\"\\n\".join(test_ids) + \"\\n\")\n",
    "    split_rows.append({\"class\":cls,\"n_total\":len(ids),\"n_train\":len(train_ids),\"n_test\":len(test_ids),\"note\":\"\"})\n",
    "\n",
    "split_report = pd.DataFrame(split_rows).sort_values(\"class\")\n",
    "display(split_report)\n",
    "split_report.to_csv(REBASE / \"02_DIRS_split_report.csv\", index=False)\n",
    "\n",
    "# 4) Build TRAIN alignments by filtering per-class slices to train IDs\n",
    "def strip_suffix(name: str, suffix: str) -> str:\n",
    "    return name[:-len(suffix)] if name.endswith(suffix) else name\n",
    "\n",
    "train_rows = []\n",
    "for aln in sorted(ALIGN_DIR.glob(\"*.aln.fasta\")):\n",
    "    cls = strip_suffix(aln.name, \".aln.fasta\")\n",
    "    tid_path = SPLIT_DIR / f\"{cls}.train.ids\"\n",
    "    if not tid_path.exists():\n",
    "        print(f\"[warn] missing train ids for {cls}\")\n",
    "        continue\n",
    "    train_ids = { ln.strip() for ln in tid_path.read_text().splitlines() if ln.strip() }\n",
    "    recs = []\n",
    "    for r in SeqIO.parse(str(aln), \"fasta\"):\n",
    "        sid = first_token(r.id or r.description)\n",
    "        if sid in train_ids:\n",
    "            recs.append(SeqRecord(Seq(str(r.seq)), id=sid, description=\"\"))\n",
    "    out = TRAIN_ALN / f\"{cls}.train.aln.fasta\"\n",
    "    if recs:\n",
    "        SeqIO.write(recs, str(out), \"fasta\")\n",
    "    train_rows.append({\"class\": cls, \"n_train_in_aln\": len(recs), \"out\": str(out)})\n",
    "\n",
    "train_report = pd.DataFrame(train_rows).sort_values(\"class\")\n",
    "display(train_report)\n",
    "train_report.to_csv(REBASE / \"03_DIRS_train_build_report.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db42901f-ed07-4811-9bc3-cbcba003a924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure hmmbuild/hmmpress/hmmstat\n",
    "assert shutil.which(\"hmmbuild\"), \"hmmbuild not found (hmmer_env)\"\n",
    "assert shutil.which(\"hmmpress\"), \"hmmpress not found (hmmer_env)\"\n",
    "assert shutil.which(\"hmmstat\"),  \"hmmstat not found (hmmer_env)\"\n",
    "\n",
    "def first_token(s): return s.split()[0] if s else s\n",
    "\n",
    "valid = set(\"ACDEFGHIKLMNPQRSTVWYBXZ-\")\n",
    "def clean_strict(seq_str: str) -> str:\n",
    "    s = seq_str.upper().replace(\".\", \"-\")\n",
    "    return \"\".join(ch if ch in valid else \"X\" for ch in s)\n",
    "\n",
    "def enforce_modal_length(records):\n",
    "    lengths = [len(r.seq) for r in records]\n",
    "    if not lengths: return [], 0, 0\n",
    "    modal_len, _ = collections.Counter(lengths).most_common(1)[0]\n",
    "    kept = [r for r in records if len(r.seq) == modal_len]\n",
    "    return kept, modal_len, len(records) - len(kept)\n",
    "\n",
    "# Clean to modal length\n",
    "rows=[]\n",
    "for aln in sorted(TRAIN_ALN.glob(\"*.train.aln.fasta\")):\n",
    "    cls = aln.stem.replace(\".train.aln\",\"\")\n",
    "    recs, repl = [], 0\n",
    "    for r in SeqIO.parse(str(aln), \"fasta\"):\n",
    "        raw = str(r.seq)\n",
    "        cleaned = clean_strict(raw)\n",
    "        repl += sum(1 for a,b in zip(raw.upper(), cleaned) if a != b)\n",
    "        recs.append(SeqRecord(Seq(cleaned), id=first_token(r.id or r.description), description=\"\"))\n",
    "    kept, modal_len, dropped = enforce_modal_length(recs)\n",
    "    out = CLEAN_ALN / f\"{cls}.train.clean.aln.fasta\"\n",
    "    if kept:\n",
    "        SeqIO.write(kept, str(out), \"fasta\")\n",
    "    rows.append({\"class\":cls,\"n_input\":len(recs),\"n_kept\":len(kept),\"dropped\":dropped,\"modal_len\":modal_len,\"replacements\":repl})\n",
    "pd.DataFrame(rows).sort_values(\"class\").to_csv(REBASE / \"04_DIRS_clean_report.csv\", index=False)\n",
    "\n",
    "# Trim poorly populated columns\n",
    "def trim_alignment(in_fa: Path, out_fa: Path, min_symbol_frac=0.10):\n",
    "    recs = list(SeqIO.parse(str(in_fa), \"fasta\"))\n",
    "    if not recs: return False\n",
    "    arr = np.array([list(str(r.seq)) for r in recs])\n",
    "    gapmask = (arr == \"-\")\n",
    "    symfrac = 1.0 - gapmask.mean(axis=0)\n",
    "    keep = (symfrac >= min_symbol_frac)\n",
    "    if not keep.any():\n",
    "        keep = (symfrac > 0.0)\n",
    "        if not keep.any(): return False\n",
    "    trimmed = [\"\".join(row[keep]) for row in arr]\n",
    "    out_recs = [SeqRecord(Seq(s), id=first_token(r.id or r.description), description=\"\")\n",
    "                for s, r in zip(trimmed, recs)]\n",
    "    SeqIO.write(out_recs, str(out_fa), \"fasta\")\n",
    "    return True\n",
    "\n",
    "for aln in sorted(CLEAN_ALN.glob(\"*.train.clean.aln.fasta\")):\n",
    "    out = TRIM_ALN / aln.name.replace(\".clean\", \"\")\n",
    "    if not out.exists():\n",
    "        _ = trim_alignment(aln, out, min_symbol_frac=0.10)\n",
    "\n",
    "# hmmbuild with fallbacks (TRIM -> CLEAN -> RAW)\n",
    "def run(cmd, log=None):\n",
    "    p = subprocess.run(shlex.split(cmd), capture_output=True, text=True)\n",
    "    if log:\n",
    "        Path(log).write_text(p.stdout + \"\\n--- STDERR ---\\n\" + p.stderr)\n",
    "    return p\n",
    "\n",
    "def hmmbuild_one(cls: str) -> dict:\n",
    "    p_trim  = TRIM_ALN  / f\"{cls}.train.aln.fasta\"\n",
    "    p_clean = CLEAN_ALN / f\"{cls}.train.clean.aln.fasta\"\n",
    "    p_raw   = TRAIN_ALN / f\"{cls}.train.aln.fasta\"\n",
    "\n",
    "    candidates = [p for p in (p_trim, p_clean, p_raw) if p.exists()]\n",
    "    chosen = None; chosen_n = 0; chosen_syms = 0\n",
    "    for cand in candidates:\n",
    "        n = sum(1 for _ in SeqIO.parse(str(cand), \"fasta\"))\n",
    "        if n >= 2:\n",
    "            chosen = cand; chosen_n = n\n",
    "            chosen_syms = sum((c != '-') for r in SeqIO.parse(str(cand), \"fasta\") for c in str(r.seq))\n",
    "            if chosen_syms > 0: break\n",
    "\n",
    "    hmm = PROFILES / f\"{cls}.hmm\"\n",
    "    log1= LOGS / f\"{cls}.hmmbuild.log\"\n",
    "    log2= LOGS / f\"{cls}.hmmbuild.retry.log\"\n",
    "\n",
    "    if chosen is None:     return {\"class\":cls,\"status\":\"skip\",\"note\":\"no_alignment_with_>=2seq\"}\n",
    "    if chosen_syms == 0:   return {\"class\":cls,\"status\":\"skip\",\"note\":f\"{chosen.name}: no non-gap symbols\"}\n",
    "\n",
    "    p1 = run(f'hmmbuild --amino --symfrac 0.2 -n \"{cls}\" --cpu 4 \"{hmm}\" \"{chosen}\"', log=str(log1))\n",
    "    if p1.returncode == 0 and hmm.exists() and hmm.stat().st_size > 0:\n",
    "        return {\"class\":cls,\"status\":\"ok\",\"note\":f\"{chosen.name} (symfrac=0.2)\"}\n",
    "\n",
    "    p2 = run(f'hmmbuild --amino --symfrac 0.0 -n \"{cls}\" --cpu 4 \"{hmm}\" \"{chosen}\"', log=str(log2))\n",
    "    if p2.returncode == 0 and hmm.exists() and hmm.stat().st_size > 0:\n",
    "        return {\"class\":cls,\"status\":\"ok\",\"note\":f\"{chosen.name} (symfrac=0.0)\"}\n",
    "\n",
    "    return {\"class\":cls,\"status\":\"fail\",\"note\":f\"hmmbuild_failed on {chosen.name}\"}\n",
    "    \n",
    "with contextlib.redirect_stdout(io.StringIO()), contextlib.redirect_stderr(io.StringIO()):\n",
    "    subprocess.run([\"hmmscan\", \"--help\"])\n",
    "\n",
    "\n",
    "slice_classes = sorted([p.stem.replace(\".train.aln\",\"\") for p in TRAIN_ALN.glob(\"*.train.aln.fasta\")])\n",
    "records = [hmmbuild_one(cls) for cls in slice_classes]\n",
    "hmr = pd.DataFrame(records).sort_values([\"status\",\"class\"])\n",
    "display(hmr)\n",
    "hmr.to_csv(REBASE / \"05_DIRS_hmmbuild_report.csv\", index=False)\n",
    "\n",
    "# Combine & press\n",
    "combined = PROFILES / \"all_classes.hmm\"\n",
    "if combined.exists(): combined.unlink()\n",
    "parts = [p for p in sorted(PROFILES.glob(\"*.hmm\")) if p.name != \"all_classes.hmm\" and p.stat().st_size > 0]\n",
    "assert parts, \"No non-empty HMMs built; check 05_DIRS_hmmbuild_report.csv and logs.\"\n",
    "\n",
    "with open(combined, \"w\") as out:\n",
    "    for p in parts:\n",
    "        s = p.read_text()\n",
    "        out.write(s if s.endswith(\"\\n\") else s + \"\\n\")\n",
    "\n",
    "dst = HMM_LIB / \"all_classes.hmm\"\n",
    "shutil.copy2(combined, dst)\n",
    "for ext in (\".h3f\",\".h3i\",\".h3m\",\".h3p\"):\n",
    "    q = Path(str(dst) + ext)\n",
    "    if q.exists(): q.unlink()\n",
    "subprocess.run([\"hmmpress\", str(dst)], check=True, capture_output=True, text=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b69dc4-b34c-4068-acd4-cdef702d5543",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[DONE] New pressed HMM lib:\", dst)\n",
    "\n",
    "# Verify models present\n",
    "stat_out = subprocess.run([\"hmmstat\", str(dst)], capture_output=True, text=True, check=True).stdout\n",
    "present = []\n",
    "for line in stat_out.splitlines():\n",
    "    if re.match(r\"^\\s*\\d+\\s+\\S+\", line):\n",
    "        present.append(line.split()[1])\n",
    "present = sorted(present)\n",
    "print(f\"[verify] {len(present)} models in pressed DB.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d98a5-d952-42e7-8edb-afb006ad3c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Held-out validation from splits ===\n",
    "\n",
    "ALL_HMM = HMM_LIB / \"all_classes.hmm\"\n",
    "assert ALL_HMM.exists(), f\"Missing pressed HMM lib: {ALL_HMM}\"\n",
    "\n",
    "# Build FASTA of all held-out test sequences\n",
    "TEST_MERGED = TMP / \"dirs_heldout_test_sequences.faa\"\n",
    "test_map = {}  # seq_id -> true_class\n",
    "\n",
    "for f in sorted(FILTERED_UPDATED_FASTAS.glob(\"*.txt\")):\n",
    "    cls = f.stem\n",
    "    tid_path = SPLIT_DIR / f\"{cls}.test.ids\"\n",
    "    if not tid_path.exists(): \n",
    "        continue\n",
    "    want = set(x.strip() for x in tid_path.read_text().splitlines() if x.strip())\n",
    "    for rec in SeqIO.parse(str(f), \"fasta\"):\n",
    "        sid = first_token(rec.id or rec.description)\n",
    "        if sid in want:\n",
    "            rec.id = sid; rec.description = \"\"\n",
    "            test_map[sid] = cls\n",
    "            SeqIO.write(rec, open(TEST_MERGED, \"a\"), \"fasta\")\n",
    "\n",
    "n_written = sum(1 for _ in SeqIO.parse(str(TEST_MERGED), \"fasta\")) if TEST_MERGED.exists() else 0\n",
    "print(f\"[held-out] wrote {n_written} sequences to {TEST_MERGED}\")\n",
    "\n",
    "# hmmscan\n",
    "tbl = RESULTS / \"hmmscan_dirs_heldout.tbl\"\n",
    "dom = RESULTS / \"hmmscan_dirs_heldout.domtbl\"\n",
    "cmd = f'hmmscan --cpu 4 --tblout \"{tbl}\" --domtblout \"{dom}\" \"{ALL_HMM}\" \"{TEST_MERGED}\"'\n",
    "print(\"$\", cmd); subprocess.run(shlex.split(cmd), check=True)\n",
    "\n",
    "# Parse best hits\n",
    "dom_cols = [\"target\",\"tacc\",\"tlen\",\"query\",\"qacc\",\"qlen\",\"fs_evalue\",\"fs_score\",\"fs_bias\",\"num\",\"of\",\n",
    "            \"dom_cevalue\",\"dom_ievalue\",\"dom_score\",\"dom_bias\",\"hmmfrom\",\"hmmto\",\"alifrom\",\"alito\",\"envfrom\",\"envto\",\"acc\",\"desc\"]\n",
    "dom_hits = pd.read_csv(dom, sep=r\"\\s+\", comment=\"#\", header=None, names=dom_cols, usecols=list(range(23)), engine=\"python\")\n",
    "hits = dom_hits.rename(columns={\"target\":\"pred_model\",\"query\":\"seq_id\",\"fs_score\":\"bit_score\",\"fs_evalue\":\"evalue\"})[\n",
    "    [\"seq_id\",\"pred_model\",\"bit_score\",\"evalue\"]\n",
    "]\n",
    "hits[\"pred_class\"] = hits[\"pred_model\"].str.extract(r'^8ca\\.([a-z]+)\\.')\n",
    "\n",
    "best = (hits.sort_values([\"seq_id\",\"bit_score\"], ascending=[True, False])\n",
    "            .groupby(\"seq_id\", as_index=False)\n",
    "            .first())\n",
    "\n",
    "truth = pd.Series(test_map, name=\"true_class\")\n",
    "full = pd.DataFrame({\"seq_id\": list(test_map.keys())}).merge(best, on=\"seq_id\", how=\"left\")\n",
    "full[\"pred_class\"] = full[\"pred_class\"].fillna(\"NO_HIT\")\n",
    "full = full.join(truth, on=\"seq_id\")\n",
    "full[\"correct\"] = (full[\"pred_class\"] == full[\"true_class\"])\n",
    "\n",
    "# metrics\n",
    "n_eval = len(full)\n",
    "n_hits = int((full[\"pred_class\"] != \"NO_HIT\").sum())\n",
    "coverage = n_hits / n_eval if n_eval else float(\"nan\")\n",
    "accuracy = full[\"correct\"].mean() if n_eval else float(\"nan\")\n",
    "print(f\"[held-out] evaluated={n_eval} | hits={n_hits} | coverage={coverage:.3f} | accuracy={accuracy:.3f}\")\n",
    "\n",
    "# confusion matrix\n",
    "cm = pd.crosstab(full[\"true_class\"], full[\"pred_class\"])\n",
    "display(cm)\n",
    "\n",
    "# save\n",
    "full_out = REBASE / \"06_dirs_heldout_predictions.csv\"\n",
    "cm_out   = REBASE / \"06_dirs_confusion_matrix.csv\"\n",
    "full.to_csv(full_out, index=False); cm.to_csv(cm_out)\n",
    "print(\"[OK] wrote\", full_out, cm_out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef124de",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIPROT_BIG = BASE / \"uniprotkb_carbonic_anhydrase_2025_08_22.fasta\"\n",
    "ALL_HMM     = HMM_LIB / \"all_classes.hmm\"\n",
    "assert UNIPROT_BIG.exists(), f\"Missing UniProt FASTA: {UNIPROT_BIG}\"\n",
    "assert ALL_HMM.exists(),     f\"Missing HMM DB: {ALL_HMM}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b023d1c-6df7-45c9-8f68-a9ff76d38e01",
   "metadata": {},
   "source": [
    "# 10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02702cc5-077d-401a-b300-8feffc296af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Classify first 10k UniProt sequences with the new HMM lib; write CSV with confidence ===\n",
    "\n",
    "N_TAKE          = 10_000\n",
    "CPU             = 4\n",
    "MIN_BITSCORE    = None   \n",
    "MAX_EVALUE      = None   \n",
    "\n",
    "def first_token(s: str) -> str:\n",
    "    return s.split()[0] if s else s\n",
    "\n",
    "# 1) Subset\n",
    "subset_fa = TMP / f\"uniprot_first_{N_TAKE}.faa\"\n",
    "with open(subset_fa, \"w\") as out:\n",
    "    for i, rec in enumerate(SeqIO.parse(str(UNIPROT_BIG), \"fasta\"), start=1):\n",
    "        rec.id = first_token(rec.id or rec.description); rec.description = \"\"\n",
    "        SeqIO.write(rec, out, \"fasta\")\n",
    "        if i >= N_TAKE: break\n",
    "\n",
    "# 2) hmmscan\n",
    "tbl = RESULTS / f\"hmmscan_uniprot_first_{N_TAKE}.tbl\"\n",
    "dom = RESULTS / f\"hmmscan_uniprot_first_{N_TAKE}.domtbl\"\n",
    "log = RESULTS / f\"hmmscan_uniprot_first_{N_TAKE}.log\"\n",
    "cmd = f'hmmscan --cpu {CPU} --noali --notextw --tblout \"{tbl}\" --domtblout \"{dom}\" \"{ALL_HMM}\" \"{subset_fa}\"'\n",
    "with open(log, \"w\") as lf:\n",
    "    subprocess.run(shlex.split(cmd), check=True, stdout=lf, stderr=lf)\n",
    "\n",
    "# 3) parse, best hit per seq, apply thresholds, compute confidence\n",
    "dom_cols = [\"target\",\"tacc\",\"tlen\",\"query\",\"qacc\",\"qlen\",\"fs_evalue\",\"fs_score\",\"fs_bias\",\"num\",\"of\",\n",
    "            \"dom_cevalue\",\"dom_ievalue\",\"dom_score\",\"dom_bias\",\"hmmfrom\",\"hmmto\",\"alifrom\",\"alito\",\"envfrom\",\"envto\",\"acc\",\"desc\"]\n",
    "dom_hits = pd.read_csv(dom, sep=r\"\\s+\", comment=\"#\", header=None, names=dom_cols, usecols=list(range(23)), engine=\"python\")\n",
    "\n",
    "hits = dom_hits.rename(columns={\n",
    "    \"target\":\"pred_model\", \"query\":\"seq_id\", \"fs_score\":\"bit_score\", \"fs_evalue\":\"evalue\"\n",
    "})[[\"seq_id\",\"pred_model\",\"bit_score\",\"evalue\"]]\n",
    "\n",
    "# collapse model -> class (e.g., 8ca.theta.45 -> theta)\n",
    "hits[\"pred_class\"] = hits[\"pred_model\"].str.extract(r'^8ca\\.([a-z]+)\\.')\n",
    "\n",
    "# best by bit score\n",
    "best = (hits.sort_values([\"seq_id\",\"bit_score\"], ascending=[True, False])\n",
    "             .groupby(\"seq_id\", as_index=False)\n",
    "             .first())\n",
    "\n",
    "# add NO_HITs & thresholds\n",
    "subset_ids = [r.id for r in SeqIO.parse(str(subset_fa), \"fasta\")]\n",
    "lab = pd.DataFrame({\"seq_id\": subset_ids}).merge(best, on=\"seq_id\", how=\"left\")\n",
    "lab[\"pred_class\"] = lab[\"pred_class\"].fillna(\"NO_HIT\")\n",
    "\n",
    "# Optional thresholds -> demote to NO_HIT\n",
    "if MIN_BITSCORE is not None:\n",
    "    lab.loc[lab[\"bit_score\"].notna() & (lab[\"bit_score\"] < MIN_BITSCORE), \"pred_class\"] = \"NO_HIT\"\n",
    "if MAX_EVALUE is not None:\n",
    "    lab.loc[lab[\"evalue\"].notna() & (lab[\"evalue\"] > MAX_EVALUE), \"pred_class\"] = \"NO_HIT\"\n",
    "\n",
    "# Confidence score: -log10(evalue) (higher is more confident); NaN for NO_HIT/empty\n",
    "def conf_from_evalue(ev):\n",
    "    try:\n",
    "        if pd.isna(ev): return np.nan\n",
    "        evf = float(ev)\n",
    "        if evf <= 0.0: return 300.0  # cap tiny e-values\n",
    "        return -np.log10(evf)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "lab[\"confidence\"] = lab[\"evalue\"].apply(conf_from_evalue)\n",
    "\n",
    "# Save detailed CSV\n",
    "out_csv = RESULTS / f\"uniprot_first_{N_TAKE}_labels_with_confidence.csv\"\n",
    "lab.to_csv(out_csv, index=False)\n",
    "print(f\"[OK] labeled {len(lab):,} seqs → {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90dc1f51-932c-4671-b5f3-9da39f537d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: distribution table & bar plot\n",
    "\n",
    "counts = (lab[\"pred_class\"].value_counts(dropna=False)\n",
    "             .rename_axis(\"class\")\n",
    "             .reset_index(name=\"count\")\n",
    "             .sort_values(\"count\", ascending=False))\n",
    "display(counts)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(counts[\"class\"], counts[\"count\"])\n",
    "plt.title(\"Distribution of HMMER-predicted Classes (first 10k sequences)\")\n",
    "plt.xlabel(\"Predicted Class\"); plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45, ha='right'); plt.tight_layout(); plt.show()\n",
    "\n",
    "counts.to_csv(RESULTS / f\"uniprot_first_{N_TAKE}_label_distribution.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9214c298-9832-4e15-995f-d83392c83320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load labeled 10k results & ensure 'confidence' exists ===\n",
    "\n",
    "LABELS  = RESULTS / \"uniprot_first_10000_labels_with_confidence.csv\"\n",
    "\n",
    "df = pd.read_csv(LABELS)\n",
    "print(f\"[load] {len(df):,} sequences\")\n",
    "\n",
    "# If confidence is missing, compute from e-value: confidence = -log10(evalue)\n",
    "if \"confidence\" not in df.columns:\n",
    "    def conf_from_evalue(ev):\n",
    "        try:\n",
    "            if pd.isna(ev): return np.nan\n",
    "            evf = float(ev)\n",
    "            if evf <= 0.0: return 300.0  # cap tiny e-values\n",
    "            return -np.log10(evf)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    df[\"confidence\"] = df[\"evalue\"].apply(conf_from_evalue)\n",
    "\n",
    "# Make a filtered frame with actual hits only\n",
    "hits = df[df[\"pred_class\"].ne(\"NO_HIT\")].copy()\n",
    "print(f\"[hits] {len(hits):,} with assigned class (exclude NO_HIT)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff62d030-1ff4-4883-8cb5-d4c7089a9952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Overall confidence distribution: histogram + ECDF ===\n",
    "\n",
    "conf = hits[\"confidence\"].dropna().values\n",
    "if conf.size == 0:\n",
    "    print(\"No confidences to plot.\")\n",
    "else:\n",
    "    # Histogram\n",
    "    plt.figure(figsize=(8,4))\n",
    "    # Choose bins up to a reasonable cap (ignore extreme 300 cap if present)\n",
    "    finite = conf[np.isfinite(conf)]\n",
    "    xmax = np.percentile(finite, 99.5) if finite.size else 10\n",
    "    bins = np.linspace(0, xmax, 40)\n",
    "    plt.hist(conf, bins=bins)\n",
    "    plt.title(\"Confidence (−log10 e-value) — Overall\")\n",
    "    plt.xlabel(\"Confidence (higher = more confident)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS / \"conf_overall_hist.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    # ECDF\n",
    "    def ecdf(vals):\n",
    "        x = np.sort(vals)\n",
    "        y = (np.arange(1, len(x)+1) / len(x)) * 100.0\n",
    "        return x, y\n",
    "\n",
    "    x, y = ecdf(conf)\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.step(x, y, where=\"post\")\n",
    "    plt.title(\"Confidence ECDF — Overall\")\n",
    "    plt.xlabel(\"Confidence (−log10 e-value)\")\n",
    "    plt.ylabel(\"Percent ≤ confidence\")\n",
    "    plt.grid(True, alpha=0.3, linestyle=\":\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS / \"conf_overall_ecdf.png\", dpi=150)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f714ba59-29cb-4f00-87e9-8f66a2f3ebc6",
   "metadata": {},
   "source": [
    "E-value (expected value) is the expected number of false matches you’d see with a score ≥ this one by chance, given the database size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290011dd-1bcc-4676-bf06-65f965da2d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Confidence by predicted class: boxplots for top-N classes ===\n",
    "\n",
    "TOP_N = 10  \n",
    "\n",
    "# Count per class and pick top-N\n",
    "counts = (hits[\"pred_class\"]\n",
    "          .value_counts()\n",
    "          .sort_values(ascending=False))\n",
    "top_classes = counts.head(TOP_N).index.tolist()\n",
    "\n",
    "# Prepare data for boxplot\n",
    "data = [hits.loc[hits[\"pred_class\"]==c, \"confidence\"].dropna().values for c in top_classes]\n",
    "\n",
    "plt.figure(figsize=(max(10, 1.0*len(top_classes)+4), 5))\n",
    "bp = plt.boxplot(data, labels=top_classes, showfliers=False)\n",
    "plt.title(f\"Confidence by Predicted Class (top {len(top_classes)} by count)\")\n",
    "plt.ylabel(\"Confidence (−log10 e-value)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS / \"conf_by_class_boxplot_topN.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "729db1f7-7a77-4762-ab92-110b5ccd5bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Per-class confidence summary + bar chart of means ===\n",
    "\n",
    "summary = (\n",
    "    hits.dropna(subset=[\"confidence\"])\n",
    "        .groupby(\"pred_class\")[\"confidence\"]\n",
    "        .agg(n=\"count\", mean=\"mean\", median=\"median\",\n",
    "             q25=lambda s: np.percentile(s, 25),\n",
    "             q75=lambda s: np.percentile(s, 75))\n",
    "        .sort_values(\"mean\", ascending=False)\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "summary_path = RESULTS / \"conf_per_class_summary.csv\"\n",
    "summary.to_csv(summary_path, index=False)\n",
    "print(\"[OK] wrote\", summary_path)\n",
    "display(summary.head(20))\n",
    "\n",
    "# Bar of mean confidence for top-M by count (to avoid tiny classes dominating)\n",
    "M = 12\n",
    "top_by_count = (hits[\"pred_class\"].value_counts().head(M).index)\n",
    "summ_plot = summary[summary[\"pred_class\"].isin(top_by_count)].copy()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(summ_plot[\"pred_class\"], summ_plot[\"mean\"])\n",
    "plt.title(\"Mean Confidence by Class (top by count)\")\n",
    "plt.ylabel(\"Mean confidence (−log10 e-value)\")\n",
    "plt.xlabel(\"Predicted class\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS / \"conf_by_class_mean_bar_topCount.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da785bd7-1c22-4603-8ee7-2e24a77487db",
   "metadata": {},
   "source": [
    "# 50k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3477e786-d64c-4f3c-9935-f0610dba6d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Classify first 10k UniProt sequences with the new HMM lib; write CSV with confidence ===\n",
    "\n",
    "N_TAKE          = 50_000\n",
    "CPU             = 4\n",
    "MIN_BITSCORE    = None   \n",
    "MAX_EVALUE      = None  \n",
    "\n",
    "def first_token(s: str) -> str:\n",
    "    return s.split()[0] if s else s\n",
    "\n",
    "# 1) Subset\n",
    "subset_fa = TMP / f\"uniprot_first_{N_TAKE}.faa\"\n",
    "with open(subset_fa, \"w\") as out:\n",
    "    for i, rec in enumerate(SeqIO.parse(str(UNIPROT_BIG), \"fasta\"), start=1):\n",
    "        rec.id = first_token(rec.id or rec.description); rec.description = \"\"\n",
    "        SeqIO.write(rec, out, \"fasta\")\n",
    "        if i >= N_TAKE: break\n",
    "\n",
    "# 2) hmmscan\n",
    "tbl = RESULTS / f\"hmmscan_uniprot_first_{N_TAKE}.tbl\"\n",
    "dom = RESULTS / f\"hmmscan_uniprot_first_{N_TAKE}.domtbl\"\n",
    "log = RESULTS / f\"hmmscan_uniprot_first_{N_TAKE}.log\"\n",
    "cmd = f'hmmscan --cpu {CPU} --noali --notextw --tblout \"{tbl}\" --domtblout \"{dom}\" \"{ALL_HMM}\" \"{subset_fa}\"'\n",
    "with open(log, \"w\") as lf:\n",
    "    subprocess.run(shlex.split(cmd), check=True, stdout=lf, stderr=lf)\n",
    "\n",
    "# 3) parse, best hit per seq, apply thresholds, compute confidence\n",
    "dom_cols = [\"target\",\"tacc\",\"tlen\",\"query\",\"qacc\",\"qlen\",\"fs_evalue\",\"fs_score\",\"fs_bias\",\"num\",\"of\",\n",
    "            \"dom_cevalue\",\"dom_ievalue\",\"dom_score\",\"dom_bias\",\"hmmfrom\",\"hmmto\",\"alifrom\",\"alito\",\"envfrom\",\"envto\",\"acc\",\"desc\"]\n",
    "dom_hits = pd.read_csv(dom, sep=r\"\\s+\", comment=\"#\", header=None, names=dom_cols, usecols=list(range(23)), engine=\"python\")\n",
    "\n",
    "hits = dom_hits.rename(columns={\n",
    "    \"target\":\"pred_model\", \"query\":\"seq_id\", \"fs_score\":\"bit_score\", \"fs_evalue\":\"evalue\"\n",
    "})[[\"seq_id\",\"pred_model\",\"bit_score\",\"evalue\"]]\n",
    "\n",
    "# collapse model -> class (e.g., 8ca.theta.45 -> theta)\n",
    "hits[\"pred_class\"] = hits[\"pred_model\"].str.extract(r'^8ca\\.([a-z]+)\\.')\n",
    "\n",
    "# best by bit score\n",
    "best = (hits.sort_values([\"seq_id\",\"bit_score\"], ascending=[True, False])\n",
    "             .groupby(\"seq_id\", as_index=False)\n",
    "             .first())\n",
    "\n",
    "# add NO_HITs & thresholds\n",
    "subset_ids = [r.id for r in SeqIO.parse(str(subset_fa), \"fasta\")]\n",
    "lab = pd.DataFrame({\"seq_id\": subset_ids}).merge(best, on=\"seq_id\", how=\"left\")\n",
    "lab[\"pred_class\"] = lab[\"pred_class\"].fillna(\"NO_HIT\")\n",
    "\n",
    "# Optional thresholds -> demote to NO_HIT\n",
    "if MIN_BITSCORE is not None:\n",
    "    lab.loc[lab[\"bit_score\"].notna() & (lab[\"bit_score\"] < MIN_BITSCORE), \"pred_class\"] = \"NO_HIT\"\n",
    "if MAX_EVALUE is not None:\n",
    "    lab.loc[lab[\"evalue\"].notna() & (lab[\"evalue\"] > MAX_EVALUE), \"pred_class\"] = \"NO_HIT\"\n",
    "\n",
    "# Confidence score: -log10(evalue) (higher is more confident); NaN for NO_HIT/empty\n",
    "def conf_from_evalue(ev):\n",
    "    try:\n",
    "        if pd.isna(ev): return np.nan\n",
    "        evf = float(ev)\n",
    "        if evf <= 0.0: return 300.0  # cap tiny e-values\n",
    "        return -np.log10(evf)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "lab[\"confidence\"] = lab[\"evalue\"].apply(conf_from_evalue)\n",
    "\n",
    "# Save detailed CSV\n",
    "out_csv = RESULTS / f\"uniprot_first_{N_TAKE}_labels_with_confidence.csv\"\n",
    "lab.to_csv(out_csv, index=False)\n",
    "print(f\"[OK] labeled {len(lab):,} seqs → {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad94f2c6-1ea0-4482-ade8-cc7ea9f20a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: distribution table & bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts = (lab[\"pred_class\"].value_counts(dropna=False)\n",
    "             .rename_axis(\"class\")\n",
    "             .reset_index(name=\"count\")\n",
    "             .sort_values(\"count\", ascending=False))\n",
    "display(counts)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(counts[\"class\"], counts[\"count\"])\n",
    "plt.title(\"Distribution of HMMER-predicted Classes (first 50k sequences)\")\n",
    "plt.xlabel(\"Predicted Class\"); plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45, ha='right'); plt.tight_layout(); plt.show()\n",
    "\n",
    "counts.to_csv(RESULTS / f\"uniprot_first_{N_TAKE}_label_distribution.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e0cdcc7-72a6-46b6-99c9-bde296e30b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load labeled 10k results & ensure 'confidence' exists ===\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "BASE    = Path(\"/mnt/c/Users/SAM/CODE/HMMR\")\n",
    "REBASE  = BASE / \"HMMR_RE\"\n",
    "RESULTS = REBASE / \"results\"\n",
    "LABELS  = RESULTS / \"uniprot_first_50000_labels_with_confidence.csv\"\n",
    "\n",
    "df = pd.read_csv(LABELS)\n",
    "print(f\"[load] {len(df):,} sequences\")\n",
    "\n",
    "# If confidence is missing, compute from e-value: confidence = -log10(evalue)\n",
    "if \"confidence\" not in df.columns:\n",
    "    def conf_from_evalue(ev):\n",
    "        try:\n",
    "            if pd.isna(ev): return np.nan\n",
    "            evf = float(ev)\n",
    "            if evf <= 0.0: return 300.0  # cap tiny e-values\n",
    "            return -np.log10(evf)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    df[\"confidence\"] = df[\"evalue\"].apply(conf_from_evalue)\n",
    "\n",
    "# Make a filtered frame with actual hits only\n",
    "hits = df[df[\"pred_class\"].ne(\"NO_HIT\")].copy()\n",
    "print(f\"[hits] {len(hits):,} with assigned class (exclude NO_HIT)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b20fab-49c1-4548-88bf-9d6acc5ea991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Overall confidence distribution: histogram + ECDF ===\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conf = hits[\"confidence\"].dropna().values\n",
    "if conf.size == 0:\n",
    "    print(\"No confidences to plot.\")\n",
    "else:\n",
    "    # Histogram\n",
    "    plt.figure(figsize=(8,4))\n",
    "    finite = conf[np.isfinite(conf)]\n",
    "    xmax = np.percentile(finite, 99.5) if finite.size else 10\n",
    "    bins = np.linspace(0, xmax, 40)\n",
    "    plt.hist(conf, bins=bins)\n",
    "    plt.title(\"Confidence (−log10 e-value) — Overall\")\n",
    "    plt.xlabel(\"Confidence (higher = more confident)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS / \"conf_overall_hist.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    # ECDF\n",
    "    def ecdf(vals):\n",
    "        x = np.sort(vals)\n",
    "        y = (np.arange(1, len(x)+1) / len(x)) * 100.0\n",
    "        return x, y\n",
    "\n",
    "    x, y = ecdf(conf)\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.step(x, y, where=\"post\")\n",
    "    plt.title(\"Confidence ECDF — Overall\")\n",
    "    plt.xlabel(\"Confidence (−log10 e-value)\")\n",
    "    plt.ylabel(\"Percent ≤ confidence\")\n",
    "    plt.grid(True, alpha=0.3, linestyle=\":\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS / \"conf_overall_ecdf.png\", dpi=150)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9906af3-eb15-4fb9-b5ad-cca5f4e53262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Confidence by predicted class: boxplots for top-N classes ===\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TOP_N = 10 \n",
    "\n",
    "# Count per class and pick top-N\n",
    "counts = (hits[\"pred_class\"]\n",
    "          .value_counts()\n",
    "          .sort_values(ascending=False))\n",
    "top_classes = counts.head(TOP_N).index.tolist()\n",
    "\n",
    "# Prepare data for boxplot\n",
    "data = [hits.loc[hits[\"pred_class\"]==c, \"confidence\"].dropna().values for c in top_classes]\n",
    "\n",
    "plt.figure(figsize=(max(10, 1.0*len(top_classes)+4), 5))\n",
    "bp = plt.boxplot(data, labels=top_classes, showfliers=False)\n",
    "plt.title(f\"Confidence by Predicted Class (top {len(top_classes)} by count)\")\n",
    "plt.ylabel(\"Confidence (−log10 e-value)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS / \"conf_by_class_boxplot_topN.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf407a05-a00c-4c87-b182-4d33ceb5a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Per-class confidence summary + bar chart of means ===\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "summary = (\n",
    "    hits.dropna(subset=[\"confidence\"])\n",
    "        .groupby(\"pred_class\")[\"confidence\"]\n",
    "        .agg(n=\"count\", mean=\"mean\", median=\"median\",\n",
    "             q25=lambda s: np.percentile(s, 25),\n",
    "             q75=lambda s: np.percentile(s, 75))\n",
    "        .sort_values(\"mean\", ascending=False)\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "summary_path = RESULTS / \"conf_per_class_summary.csv\"\n",
    "summary.to_csv(summary_path, index=False)\n",
    "print(\"[OK] wrote\", summary_path)\n",
    "display(summary.head(20))\n",
    "\n",
    "# Bar of mean confidence for top-M by count (to avoid tiny classes dominating)\n",
    "M = 12\n",
    "top_by_count = (hits[\"pred_class\"].value_counts().head(M).index)\n",
    "summ_plot = summary[summary[\"pred_class\"].isin(top_by_count)].copy()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(summ_plot[\"pred_class\"], summ_plot[\"mean\"])\n",
    "plt.title(\"Mean Confidence by Class (top by count)\")\n",
    "plt.ylabel(\"Mean confidence (−log10 e-value)\")\n",
    "plt.xlabel(\"Predicted class\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS / \"conf_by_class_mean_bar_topCount.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feaa63d-3d79-4665-a270-5dce2937e145",
   "metadata": {},
   "source": [
    "# 100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc070072-8ecf-4799-ac39-ad8e78d3f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd460526-1d9f-46ba-9c04-b3924254bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Classify first 10k UniProt sequences with the new HMM lib; write CSV with confidence ===\n",
    "\n",
    "N_TAKE          = 100_000\n",
    "CPU             = 8\n",
    "MIN_BITSCORE    = None   # e.g., 25.0 (optional)\n",
    "MAX_EVALUE      = None   # e.g., 1e-5 (optional)\n",
    "\n",
    "def first_token(s: str) -> str:\n",
    "    return s.split()[0] if s else s\n",
    "\n",
    "# 1) Subset\n",
    "subset_fa = TMP / f\"uniprot_first_{N_TAKE}.faa\"\n",
    "with open(subset_fa, \"w\") as out:\n",
    "    for i, rec in enumerate(SeqIO.parse(str(UNIPROT_BIG), \"fasta\"), start=1):\n",
    "        rec.id = first_token(rec.id or rec.description); rec.description = \"\"\n",
    "        SeqIO.write(rec, out, \"fasta\")\n",
    "        if i >= N_TAKE: break\n",
    "\n",
    "# 2) hmmscan\n",
    "tbl = RESULTS / f\"hmmscan_uniprot_first_{N_TAKE}.tbl\"\n",
    "dom = RESULTS / f\"hmmscan_uniprot_first_{N_TAKE}.domtbl\"\n",
    "log = RESULTS / f\"hmmscan_uniprot_first_{N_TAKE}.log\"\n",
    "cmd = f'hmmscan --cpu {CPU} --noali --notextw --tblout \"{tbl}\" --domtblout \"{dom}\" \"{ALL_HMM}\" \"{subset_fa}\"'\n",
    "with open(log, \"w\") as lf:\n",
    "    subprocess.run(shlex.split(cmd), check=True, stdout=lf, stderr=lf)\n",
    "\n",
    "# 3) parse, best hit per seq, apply thresholds, compute confidence\n",
    "dom_cols = [\"target\",\"tacc\",\"tlen\",\"query\",\"qacc\",\"qlen\",\"fs_evalue\",\"fs_score\",\"fs_bias\",\"num\",\"of\",\n",
    "            \"dom_cevalue\",\"dom_ievalue\",\"dom_score\",\"dom_bias\",\"hmmfrom\",\"hmmto\",\"alifrom\",\"alito\",\"envfrom\",\"envto\",\"acc\",\"desc\"]\n",
    "dom_hits = pd.read_csv(dom, sep=r\"\\s+\", comment=\"#\", header=None, names=dom_cols, usecols=list(range(23)), engine=\"python\")\n",
    "\n",
    "hits = dom_hits.rename(columns={\n",
    "    \"target\":\"pred_model\", \"query\":\"seq_id\", \"fs_score\":\"bit_score\", \"fs_evalue\":\"evalue\"\n",
    "})[[\"seq_id\",\"pred_model\",\"bit_score\",\"evalue\"]]\n",
    "\n",
    "# collapse model -> class (e.g., 8ca.theta.45 -> theta)\n",
    "hits[\"pred_class\"] = hits[\"pred_model\"].str.extract(r'^8ca\\.([a-z]+)\\.')\n",
    "\n",
    "# best by bit score\n",
    "best = (hits.sort_values([\"seq_id\",\"bit_score\"], ascending=[True, False])\n",
    "             .groupby(\"seq_id\", as_index=False)\n",
    "             .first())\n",
    "\n",
    "# add NO_HITs & thresholds\n",
    "subset_ids = [r.id for r in SeqIO.parse(str(subset_fa), \"fasta\")]\n",
    "lab = pd.DataFrame({\"seq_id\": subset_ids}).merge(best, on=\"seq_id\", how=\"left\")\n",
    "lab[\"pred_class\"] = lab[\"pred_class\"].fillna(\"NO_HIT\")\n",
    "\n",
    "# Optional thresholds -> demote to NO_HIT\n",
    "if MIN_BITSCORE is not None:\n",
    "    lab.loc[lab[\"bit_score\"].notna() & (lab[\"bit_score\"] < MIN_BITSCORE), \"pred_class\"] = \"NO_HIT\"\n",
    "if MAX_EVALUE is not None:\n",
    "    lab.loc[lab[\"evalue\"].notna() & (lab[\"evalue\"] > MAX_EVALUE), \"pred_class\"] = \"NO_HIT\"\n",
    "\n",
    "# Confidence score: -log10(evalue) (higher is more confident); NaN for NO_HIT/empty\n",
    "def conf_from_evalue(ev):\n",
    "    try:\n",
    "        if pd.isna(ev): return np.nan\n",
    "        evf = float(ev)\n",
    "        if evf <= 0.0: return 300.0  # cap tiny e-values\n",
    "        return -np.log10(evf)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "lab[\"confidence\"] = lab[\"evalue\"].apply(conf_from_evalue)\n",
    "\n",
    "# Save detailed CSV\n",
    "out_csv = RESULTS / f\"uniprot_first_{N_TAKE}_labels_with_confidence.csv\"\n",
    "lab.to_csv(out_csv, index=False)\n",
    "print(f\"[OK] labeled {len(lab):,} seqs → {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49915009-4108-4022-ad96-1713ddd840f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: distribution table & bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts = (lab[\"pred_class\"].value_counts(dropna=False)\n",
    "             .rename_axis(\"class\")\n",
    "             .reset_index(name=\"count\")\n",
    "             .sort_values(\"count\", ascending=False))\n",
    "display(counts)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(counts[\"class\"], counts[\"count\"])\n",
    "plt.title(\"Distribution of HMMER-predicted Classes (first 100k sequences)\")\n",
    "plt.xlabel(\"Predicted Class\"); plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45, ha='right'); plt.tight_layout(); plt.show()\n",
    "\n",
    "counts.to_csv(RESULTS / f\"uniprot_first_{N_TAKE}_label_distribution.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2590d428-3dad-43e0-8ae7-b4ddee812b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load labeled 10k results & ensure 'confidence' exists ===\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "BASE    = Path(\"/mnt/c/Users/SAM/CODE/HMMR\")\n",
    "REBASE  = BASE / \"HMMR_RE\"\n",
    "RESULTS = REBASE / \"results\"\n",
    "LABELS  = RESULTS / \"uniprot_first_100000_labels_with_confidence.csv\"\n",
    "\n",
    "df = pd.read_csv(LABELS)\n",
    "print(f\"[load] {len(df):,} sequences\")\n",
    "\n",
    "# If confidence is missing, compute from e-value: confidence = -log10(evalue)\n",
    "if \"confidence\" not in df.columns:\n",
    "    def conf_from_evalue(ev):\n",
    "        try:\n",
    "            if pd.isna(ev): return np.nan\n",
    "            evf = float(ev)\n",
    "            if evf <= 0.0: return 300.0  # cap tiny e-values\n",
    "            return -np.log10(evf)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    df[\"confidence\"] = df[\"evalue\"].apply(conf_from_evalue)\n",
    "\n",
    "# Make a filtered frame with actual hits only\n",
    "hits = df[df[\"pred_class\"].ne(\"NO_HIT\")].copy()\n",
    "print(f\"[hits] {len(hits):,} with assigned class (exclude NO_HIT)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28db31-7556-4ea0-b56c-daa67d9700fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Overall confidence distribution: histogram + ECDF ===\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conf = hits[\"confidence\"].dropna().values\n",
    "if conf.size == 0:\n",
    "    print(\"No confidences to plot.\")\n",
    "else:\n",
    "    # Histogram\n",
    "    plt.figure(figsize=(8,4))\n",
    "    finite = conf[np.isfinite(conf)]\n",
    "    xmax = np.percentile(finite, 99.5) if finite.size else 10\n",
    "    bins = np.linspace(0, xmax, 40)\n",
    "    plt.hist(conf, bins=bins)\n",
    "    plt.title(\"Confidence (−log10 e-value) — Overall\")\n",
    "    plt.xlabel(\"Confidence (higher = more confident)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS / \"conf_overall_hist.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    # ECDF\n",
    "    def ecdf(vals):\n",
    "        x = np.sort(vals)\n",
    "        y = (np.arange(1, len(x)+1) / len(x)) * 100.0\n",
    "        return x, y\n",
    "\n",
    "    x, y = ecdf(conf)\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.step(x, y, where=\"post\")\n",
    "    plt.title(\"Confidence ECDF — Overall\")\n",
    "    plt.xlabel(\"Confidence (−log10 e-value)\")\n",
    "    plt.ylabel(\"Percent ≤ confidence\")\n",
    "    plt.grid(True, alpha=0.3, linestyle=\":\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS / \"conf_overall_ecdf.png\", dpi=150)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c07031e3-9fe9-41ee-8336-b00bf6c1e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Confidence by predicted class: boxplots for top-N classes ===\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TOP_N = 10  # change if you want more/less classes in the figure\n",
    "\n",
    "# Count per class and pick top-N\n",
    "counts = (hits[\"pred_class\"]\n",
    "          .value_counts()\n",
    "          .sort_values(ascending=False))\n",
    "top_classes = counts.head(TOP_N).index.tolist()\n",
    "\n",
    "# Prepare data for boxplot\n",
    "data = [hits.loc[hits[\"pred_class\"]==c, \"confidence\"].dropna().values for c in top_classes]\n",
    "\n",
    "plt.figure(figsize=(max(10, 1.0*len(top_classes)+4), 5))\n",
    "bp = plt.boxplot(data, labels=top_classes, showfliers=False)\n",
    "plt.title(f\"Confidence by Predicted Class (top {len(top_classes)} by count)\")\n",
    "plt.ylabel(\"Confidence (−log10 e-value)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS / \"conf_by_class_boxplot_topN.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abdae216-b7f3-44f0-86ad-c56f5886161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Per-class confidence summary + bar chart of means ===\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "summary = (\n",
    "    hits.dropna(subset=[\"confidence\"])\n",
    "        .groupby(\"pred_class\")[\"confidence\"]\n",
    "        .agg(n=\"count\", mean=\"mean\", median=\"median\",\n",
    "             q25=lambda s: np.percentile(s, 25),\n",
    "             q75=lambda s: np.percentile(s, 75))\n",
    "        .sort_values(\"mean\", ascending=False)\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "summary_path = RESULTS / \"conf_per_class_summary.csv\"\n",
    "summary.to_csv(summary_path, index=False)\n",
    "print(\"[OK] wrote\", summary_path)\n",
    "display(summary.head(20))\n",
    "\n",
    "# Bar of mean confidence for top-M by count (to avoid tiny classes dominating)\n",
    "M = 12\n",
    "top_by_count = (hits[\"pred_class\"].value_counts().head(M).index)\n",
    "summ_plot = summary[summary[\"pred_class\"].isin(top_by_count)].copy()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(summ_plot[\"pred_class\"], summ_plot[\"mean\"])\n",
    "plt.title(\"Mean Confidence by Class (top by count)\")\n",
    "plt.ylabel(\"Mean confidence (−log10 e-value)\")\n",
    "plt.xlabel(\"Predicted class\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS / \"conf_by_class_mean_bar_topCount.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f251d6-349e-4628-9542-a579b60d87ad",
   "metadata": {},
   "source": [
    "# 150k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc713f2-bc70-442c-b36a-a6081a4ff795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Classify first 150k UniProt sequences with the new HMM lib; write CSV with confidence ===\n",
    "\n",
    "\n",
    "N_TAKE          = 150_000\n",
    "CPU             = 8\n",
    "MIN_BITSCORE    = None   # e.g., 25.0 (optional)\n",
    "MAX_EVALUE      = None   # e.g., 1e-5 (optional)\n",
    "\n",
    "def first_token(s: str) -> str:\n",
    "    return s.split()[0] if s else s\n",
    "\n",
    "# 1) Subset\n",
    "subset_fa = TMP / f\"uniprot_first_{N_TAKE}.faa\"\n",
    "with open(subset_fa, \"w\") as out:\n",
    "    for i, rec in enumerate(SeqIO.parse(str(UNIPROT_BIG), \"fasta\"), start=1):\n",
    "        rec.id = first_token(rec.id or rec.description); rec.description = \"\"\n",
    "        SeqIO.write(rec, out, \"fasta\")\n",
    "        if i >= N_TAKE: break\n",
    "\n",
    "# 2) hmmscan\n",
    "tbl = RESULTS / f\"hmmscan_uniprot_first_{N_TAKE}.tbl\"\n",
    "dom = RESULTS / f\"hmmscan_uniprot_first_{N_TAKE}.domtbl\"\n",
    "log = RESULTS / f\"hmmscan_uniprot_first_{N_TAKE}.log\"\n",
    "cmd = f'hmmscan --cpu {CPU} --noali --notextw --tblout \"{tbl}\" --domtblout \"{dom}\" \"{ALL_HMM}\" \"{subset_fa}\"'\n",
    "with open(log, \"w\") as lf:\n",
    "    subprocess.run(shlex.split(cmd), check=True, stdout=lf, stderr=lf)\n",
    "\n",
    "# 3) parse, best hit per seq, apply thresholds, compute confidence\n",
    "dom_cols = [\"target\",\"tacc\",\"tlen\",\"query\",\"qacc\",\"qlen\",\"fs_evalue\",\"fs_score\",\"fs_bias\",\"num\",\"of\",\n",
    "            \"dom_cevalue\",\"dom_ievalue\",\"dom_score\",\"dom_bias\",\"hmmfrom\",\"hmmto\",\"alifrom\",\"alito\",\"envfrom\",\"envto\",\"acc\",\"desc\"]\n",
    "dom_hits = pd.read_csv(dom, sep=r\"\\s+\", comment=\"#\", header=None, names=dom_cols, usecols=list(range(23)), engine=\"python\")\n",
    "\n",
    "hits = dom_hits.rename(columns={\n",
    "    \"target\":\"pred_model\", \"query\":\"seq_id\", \"fs_score\":\"bit_score\", \"fs_evalue\":\"evalue\"\n",
    "})[[\"seq_id\",\"pred_model\",\"bit_score\",\"evalue\"]]\n",
    "\n",
    "# collapse model -> class (e.g., 8ca.theta.45 -> theta)\n",
    "hits[\"pred_class\"] = hits[\"pred_model\"].str.extract(r'^8ca\\.([a-z]+)\\.')\n",
    "\n",
    "# best by bit score\n",
    "best = (hits.sort_values([\"seq_id\",\"bit_score\"], ascending=[True, False])\n",
    "             .groupby(\"seq_id\", as_index=False)\n",
    "             .first())\n",
    "\n",
    "# add NO_HITs & thresholds\n",
    "subset_ids = [r.id for r in SeqIO.parse(str(subset_fa), \"fasta\")]\n",
    "lab = pd.DataFrame({\"seq_id\": subset_ids}).merge(best, on=\"seq_id\", how=\"left\")\n",
    "lab[\"pred_class\"] = lab[\"pred_class\"].fillna(\"NO_HIT\")\n",
    "\n",
    "# Optional thresholds -> demote to NO_HIT\n",
    "if MIN_BITSCORE is not None:\n",
    "    lab.loc[lab[\"bit_score\"].notna() & (lab[\"bit_score\"] < MIN_BITSCORE), \"pred_class\"] = \"NO_HIT\"\n",
    "if MAX_EVALUE is not None:\n",
    "    lab.loc[lab[\"evalue\"].notna() & (lab[\"evalue\"] > MAX_EVALUE), \"pred_class\"] = \"NO_HIT\"\n",
    "\n",
    "# Confidence score: -log10(evalue) (higher is more confident); NaN for NO_HIT/empty\n",
    "def conf_from_evalue(ev):\n",
    "    try:\n",
    "        if pd.isna(ev): return np.nan\n",
    "        evf = float(ev)\n",
    "        if evf <= 0.0: return 300.0  # cap tiny e-values\n",
    "        return -np.log10(evf)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "lab[\"confidence\"] = lab[\"evalue\"].apply(conf_from_evalue)\n",
    "\n",
    "# Save detailed CSV\n",
    "out_csv = RESULTS / f\"uniprot_first_{N_TAKE}_labels_with_confidence.csv\"\n",
    "lab.to_csv(out_csv, index=False)\n",
    "print(f\"[OK] labeled {len(lab):,} seqs → {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc18d22a-a667-4fc3-b833-6c72605c4bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: distribution table & bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counts = (lab[\"pred_class\"].value_counts(dropna=False)\n",
    "             .rename_axis(\"class\")\n",
    "             .reset_index(name=\"count\")\n",
    "             .sort_values(\"count\", ascending=False))\n",
    "display(counts)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(counts[\"class\"], counts[\"count\"])\n",
    "plt.title(\"Distribution of HMMER-predicted Classes (first 150k sequences)\")\n",
    "plt.xlabel(\"Predicted Class\"); plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45, ha='right'); plt.tight_layout(); plt.show()\n",
    "\n",
    "counts.to_csv(RESULTS / f\"uniprot_first_{N_TAKE}_label_distribution.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7dd072bf-5778-4a95-9a41-9a838ee60222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load labeled 10k results & ensure 'confidence' exists ===\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "BASE    = Path(\"/mnt/c/Users/SAM/CODE/HMMR\")\n",
    "REBASE  = BASE / \"HMMR_RE\"\n",
    "RESULTS = REBASE / \"results\"\n",
    "LABELS  = RESULTS / \"uniprot_first_150000_labels_with_confidence.csv\"\n",
    "\n",
    "df = pd.read_csv(LABELS)\n",
    "print(f\"[load] {len(df):,} sequences\")\n",
    "\n",
    "# If confidence is missing, compute from e-value: confidence = -log10(evalue)\n",
    "if \"confidence\" not in df.columns:\n",
    "    def conf_from_evalue(ev):\n",
    "        try:\n",
    "            if pd.isna(ev): return np.nan\n",
    "            evf = float(ev)\n",
    "            if evf <= 0.0: return 300.0  # cap tiny e-values\n",
    "            return -np.log10(evf)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    df[\"confidence\"] = df[\"evalue\"].apply(conf_from_evalue)\n",
    "\n",
    "# Make a filtered frame with actual hits only\n",
    "hits = df[df[\"pred_class\"].ne(\"NO_HIT\")].copy()\n",
    "print(f\"[hits] {len(hits):,} with assigned class (exclude NO_HIT)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7e910-ae61-4df5-aa20-de04a8e3d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Overall confidence distribution: histogram + ECDF ===\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conf = hits[\"confidence\"].dropna().values\n",
    "if conf.size == 0:\n",
    "    print(\"No confidences to plot.\")\n",
    "else:\n",
    "    # Histogram\n",
    "    plt.figure(figsize=(8,4))\n",
    "\n",
    "    finite = conf[np.isfinite(conf)]\n",
    "    xmax = np.percentile(finite, 99.5) if finite.size else 10\n",
    "    bins = np.linspace(0, xmax, 40)\n",
    "    plt.hist(conf, bins=bins)\n",
    "    plt.title(\"Confidence (−log10 e-value) — Overall\")\n",
    "    plt.xlabel(\"Confidence (higher = more confident)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS / \"conf_overall_hist.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    # ECDF\n",
    "    def ecdf(vals):\n",
    "        x = np.sort(vals)\n",
    "        y = (np.arange(1, len(x)+1) / len(x)) * 100.0\n",
    "        return x, y\n",
    "\n",
    "    x, y = ecdf(conf)\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.step(x, y, where=\"post\")\n",
    "    plt.title(\"Confidence ECDF — Overall\")\n",
    "    plt.xlabel(\"Confidence (−log10 e-value)\")\n",
    "    plt.ylabel(\"Percent ≤ confidence\")\n",
    "    plt.grid(True, alpha=0.3, linestyle=\":\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS / \"conf_overall_ecdf.png\", dpi=150)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3536e21a-5ea0-4bb2-8aef-2b1ccbdaf1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Confidence by predicted class: boxplots for top-N classes ===\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TOP_N = 10  \n",
    "\n",
    "# Count per class and pick top-N\n",
    "counts = (hits[\"pred_class\"]\n",
    "          .value_counts()\n",
    "          .sort_values(ascending=False))\n",
    "top_classes = counts.head(TOP_N).index.tolist()\n",
    "\n",
    "# Prepare data for boxplot\n",
    "data = [hits.loc[hits[\"pred_class\"]==c, \"confidence\"].dropna().values for c in top_classes]\n",
    "\n",
    "plt.figure(figsize=(max(10, 1.0*len(top_classes)+4), 5))\n",
    "bp = plt.boxplot(data, labels=top_classes, showfliers=False)\n",
    "plt.title(f\"Confidence by Predicted Class (top {len(top_classes)} by count)\")\n",
    "plt.ylabel(\"Confidence (−log10 e-value)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS / \"conf_by_class_boxplot_topN.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b69a7c8-c194-4cc0-9856-6c375606ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Per-class confidence summary + bar chart of means ===\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "summary = (\n",
    "    hits.dropna(subset=[\"confidence\"])\n",
    "        .groupby(\"pred_class\")[\"confidence\"]\n",
    "        .agg(n=\"count\", mean=\"mean\", median=\"median\",\n",
    "             q25=lambda s: np.percentile(s, 25),\n",
    "             q75=lambda s: np.percentile(s, 75))\n",
    "        .sort_values(\"mean\", ascending=False)\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "summary_path = RESULTS / \"conf_per_class_summary.csv\"\n",
    "summary.to_csv(summary_path, index=False)\n",
    "print(\"[OK] wrote\", summary_path)\n",
    "display(summary.head(20))\n",
    "\n",
    "# Bar of mean confidence for top-M by count (to avoid tiny classes dominating)\n",
    "M = 12\n",
    "top_by_count = (hits[\"pred_class\"].value_counts().head(M).index)\n",
    "summ_plot = summary[summary[\"pred_class\"].isin(top_by_count)].copy()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(summ_plot[\"pred_class\"], summ_plot[\"mean\"])\n",
    "plt.title(\"Mean Confidence by Class (top by count)\")\n",
    "plt.ylabel(\"Mean confidence (−log10 e-value)\")\n",
    "plt.xlabel(\"Predicted class\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS / \"conf_by_class_mean_bar_topCount.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fae3842-821a-4555-8e4a-c9bd5095630a",
   "metadata": {},
   "source": [
    "# Consensus w/ Clustal O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f71bb6c-c851-44ee-886b-622f3fcdf2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Sanity check: Did training sequences appear in the labeling CSV, and were they labeled correctly? ===\n",
    "\n",
    "\n",
    "# 1) Point to the labeling CSV \n",
    "LABELS_CSV = RESULTS / \"uniprot_first_150000_labels_with_confidence.csv\"   \n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def first_token(s: str) -> str:\n",
    "    return (s or \"\").split()[0]\n",
    "\n",
    "def extract_simple_class(model_or_class: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize a model or class string to the simple class name.\n",
    "    Examples:\n",
    "      '8ca.alpha.45' -> 'alpha'\n",
    "      'alpha'        -> 'alpha'\n",
    "    \"\"\"\n",
    "    if pd.isna(model_or_class):\n",
    "        return None\n",
    "    m = re.match(r'^8ca\\.([a-z]+)\\.', str(model_or_class))\n",
    "    return m.group(1) if m else str(model_or_class)\n",
    "\n",
    "# ---------------- Load labeled CSV ----------------\n",
    "assert LABELS_CSV.exists(), f\"Labels CSV not found: {LABELS_CSV}\"\n",
    "df = pd.read_csv(LABELS_CSV)\n",
    "# Ensure expected columns exist\n",
    "for col in [\"seq_id\", \"pred_class\", \"pred_model\", \"bit_score\", \"evalue\", \"confidence\"]:\n",
    "    if col not in df.columns:\n",
    "        # tolerate older CSVs (without confidence)\n",
    "        if col == \"confidence\":\n",
    "            df[\"confidence\"] = np.nan\n",
    "        else:\n",
    "            raise ValueError(f\"Expected column '{col}' not found in {LABELS_CSV}\")\n",
    "\n",
    "# Normalize predicted class to simple form\n",
    "df[\"pred_class_simple\"] = df[\"pred_class\"].apply(extract_simple_class)\n",
    "\n",
    "# ---------------- Build training ID → class map from DIRS ----------------\n",
    "train_id_to_class = {}   # seq_id -> simple_class\n",
    "train_dupe_ids = set()   # track if an ID appears in more than one class (shouldn't)\n",
    "\n",
    "for d in DIRS:\n",
    "    d = Path(d)\n",
    "    assert d.exists(), f\"Missing training folder: {d}\"\n",
    "    for ext in (\"*.txt\", \"*.fa\", \"*.fasta\", \"*.faa\", \"*.fas\"):\n",
    "        for fp in d.glob(ext):\n",
    "            # Class name from filename stem, normalize to simple class\n",
    "            cls_simple = extract_simple_class(fp.stem)\n",
    "            for r in SeqIO.parse(str(fp), \"fasta\"):\n",
    "                rid = first_token(r.id or r.description)\n",
    "                if rid in train_id_to_class and train_id_to_class[rid] != cls_simple:\n",
    "                    train_dupe_ids.add(rid)\n",
    "                train_id_to_class.setdefault(rid, cls_simple)\n",
    "\n",
    "if train_dupe_ids:\n",
    "    print(f\"[warn] {len(train_dupe_ids)} training IDs occurred under multiple classes. Showing a few:\",\n",
    "          sorted(list(train_dupe_ids))[:5])\n",
    "\n",
    "# ---------------- Intersect training IDs with labeled CSV ----------------\n",
    "csv_ids = set(df[\"seq_id\"].astype(str))\n",
    "train_ids = set(train_id_to_class.keys())\n",
    "overlap_ids = csv_ids & train_ids\n",
    "\n",
    "print(f\"[info] Labeled CSV rows: {len(df):,}\")\n",
    "print(f\"[info] Unique seq_ids in CSV: {len(csv_ids):,}\")\n",
    "print(f\"[info] Training IDs total: {len(train_ids):,}\")\n",
    "print(f\"[info] Overlap (training IDs found in CSV): {len(overlap_ids):,}\")\n",
    "\n",
    "if len(overlap_ids) == 0:\n",
    "    print(\"No training sequences found in the labeled CSV. (This is expected, UniProt set should not contain training IDs.)\")\n",
    "else:\n",
    "    # Build a frame of overlaps with truth vs prediction\n",
    "    truth = pd.DataFrame({\n",
    "        \"seq_id\": list(overlap_ids),\n",
    "        \"true_class_simple\": [train_id_to_class[sid] for sid in overlap_ids]\n",
    "    })\n",
    "    merged = truth.merge(\n",
    "        df[[\"seq_id\", \"pred_class_simple\", \"pred_class\", \"pred_model\", \"bit_score\", \"evalue\", \"confidence\"]],\n",
    "        on=\"seq_id\", how=\"left\"\n",
    "    )\n",
    "    merged[\"correct\"] = (merged[\"pred_class_simple\"] == merged[\"true_class_simple\"])\n",
    "\n",
    "    # Summary metrics\n",
    "    total = len(merged)\n",
    "    nohit = int((merged[\"pred_class_simple\"] == \"NO_HIT\").sum())  # unlikely; pred_class_simple could be NO_HIT\n",
    "    acc = float(merged[\"correct\"].mean()) if total else float(\"nan\")\n",
    "\n",
    "    print(f\"[overlap] evaluated={total} | accuracy={acc:.3f}\")\n",
    "    # Per-class confusion on overlaps\n",
    "    cm = pd.crosstab(merged[\"true_class_simple\"], merged[\"pred_class_simple\"], dropna=False)\n",
    "    display(cm)\n",
    "\n",
    "    # Any errors to inspect?\n",
    "    wrong = merged[~merged[\"correct\"]].sort_values([\"true_class_simple\",\"pred_class_simple\",\"confidence\"], ascending=[True, True, False])\n",
    "    if not wrong.empty:\n",
    "        print(f\"[overlap] misclassified rows: {len(wrong)} (showing up to 10)\")\n",
    "        display(wrong.head(10))\n",
    "    else:\n",
    "        print(\"[overlap] No misclassifications among overlapped training IDs.\")\n",
    "\n",
    "    # Save detailed validation table\n",
    "    out_csv = RESULTS / \"training_overlap_validation.csv\"\n",
    "    merged.sort_values([\"true_class_simple\",\"correct\",\"confidence\"], ascending=[True, False, False]).to_csv(out_csv, index=False)\n",
    "    print(\"[OK] wrote\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109388d0-d734-46c2-a92f-05c3ab0ae042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Build per-class MSAs from labeled sets in DIRS, then compute majority consensus for each class ===\n",
    "\n",
    "def first_token(s): return (s or \"\").split()[0]\n",
    "\n",
    "# Collect all per-class sequences (merge & dedup by ID)\n",
    "class_to_records = {}\n",
    "for d in DIRS:\n",
    "    for ext in (\"*.txt\",\"*.fa\",\"*.fasta\",\"*.faa\",\"*.fas\"):\n",
    "        for fp in Path(d).glob(ext):\n",
    "            cls = fp.stem  # e.g., 8ca.alpha.45\n",
    "            bucket = class_to_records.setdefault(cls, {})\n",
    "            for r in SeqIO.parse(str(fp), \"fasta\"):\n",
    "                rid = first_token(r.id or r.description)\n",
    "                if rid not in bucket:\n",
    "                    bucket[rid] = SeqRecord(Seq(str(r.seq)), id=rid, description=\"\")\n",
    "\n",
    "# Build per-class MSA with clustalo\n",
    "def run(cmd): \n",
    "    return subprocess.run(shlex.split(cmd), check=True, capture_output=True, text=True)\n",
    "\n",
    "for cls, id2rec in sorted(class_to_records.items()):\n",
    "    recs = list(id2rec.values())\n",
    "    if len(recs) < 2:\n",
    "        continue\n",
    "    in_fa  = ALIGN / f\"{cls}.in.fasta\"\n",
    "    out_fa = ALIGN / f\"{cls}.aln.fasta\"\n",
    "    SeqIO.write(recs, str(in_fa), \"fasta\")\n",
    "    run(f'{clo} -i \"{in_fa}\" -o \"{out_fa}\" --force --threads=4 --seqtype=Protein --output-order=input-order')\n",
    "\n",
    "# Majority-rule consensus\n",
    "def majority_consensus_from_alignment(aln_fa: Path, threshold: float = 0.5) -> str:\n",
    "    recs = list(SeqIO.parse(str(aln_fa), \"fasta\"))\n",
    "    seqs = [str(r.seq) for r in recs]\n",
    "    L = max(len(s) for s in seqs)\n",
    "    cons = []\n",
    "    for j in range(L):\n",
    "        col = [s[j] if j < len(s) else \"-\" for s in seqs]\n",
    "        letters = [c for c in col if c not in \"-.\"]\n",
    "        if not letters:\n",
    "            cons.append(\"-\"); continue\n",
    "        vals, counts = np.unique(letters, return_counts=True)\n",
    "        i = int(np.argmax(counts))\n",
    "        frac = counts[i] / float(len(letters))\n",
    "        cons.append(vals[i] if frac >= threshold else \"X\")\n",
    "    return \"\".join(cons)\n",
    "\n",
    "# Write consensus FASTA per class\n",
    "consensus_paths = {}\n",
    "for aln in sorted(ALIGN.glob(\"*.aln.fasta\")):\n",
    "    cls = aln.stem.replace(\".aln\",\"\")  # e.g., 8ca.alpha.45\n",
    "    cons = majority_consensus_from_alignment(aln, threshold=0.5)\n",
    "    fa = CONS / f\"{cls}.consensus.fasta\"\n",
    "    with open(fa, \"w\") as f:\n",
    "        f.write(f\">{cls}\\n\")\n",
    "        for i in range(0, len(cons), 80):\n",
    "            f.write(cons[i:i+80] + \"\\n\")\n",
    "    consensus_paths[cls] = fa\n",
    "\n",
    "print(f\"[OK] wrote {len(consensus_paths)} consensus sequences to {CONS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81073b24-ec4a-4998-a109-06ac09fa74b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Predict labels for 150k by aligning each query to every class consensus ===\n",
    "\n",
    "# Input queries (150k)\n",
    "QUERIES = REBASE / \"tmp\" / \"uniprot_first_150000.faa\"  \n",
    "\n",
    "# Scoring for global alignment (simple, fast-ish)\n",
    "MATCH, MISMATCH, GAP_OPEN, GAP_EXT = 1, -1, -5, -1\n",
    "\n",
    "# Minimum identity to accept a class; otherwise NO_HIT\n",
    "MIN_IDENTITY = 0.30    # 30% global identity to the consensus (tune as you like)\n",
    "\n",
    "# Parallelism\n",
    "N_PROC = max(1, (os.cpu_count() or 4) - 1)\n",
    "\n",
    "# Load consensus sequences\n",
    "consensus = []  # [(cls, simple_class, seqstr)]\n",
    "def simple_class(cls):  # '8ca.alpha.45' -> 'alpha'\n",
    "    import re\n",
    "    m = re.match(r'^8ca\\.([a-z]+)\\.', cls)\n",
    "    return m.group(1) if m else cls\n",
    "\n",
    "for fa in sorted(CONS.glob(\"*.consensus.fasta\")):\n",
    "    cls = fa.stem.replace(\".consensus\",\"\")\n",
    "    seq = str(next(SeqIO.parse(str(fa), \"fasta\")).seq).replace(\"-\", \"\")\n",
    "    consensus.append((cls, simple_class(cls), seq))\n",
    "\n",
    "assert consensus, \"No consensus files found.\"\n",
    "\n",
    "# Worker to classify one sequence\n",
    "def classify_one(args):\n",
    "    rec_id, seq = args\n",
    "    best = None\n",
    "    for cls, simp, cseq in consensus:\n",
    "        # Global alignment to consensus\n",
    "        # score_only speeds up; then compute identity from an explicit align once for the best\n",
    "        alns = pairwise2.align.globalms(seq, cseq, MATCH, MISMATCH, GAP_OPEN, GAP_EXT, one_alignment_only=True)\n",
    "        if not alns:\n",
    "            continue\n",
    "        score, a, b = alns[0].score, alns[0].seqA, alns[0].seqB\n",
    "        # identity = matches / alignment length (excluding gap-gap)\n",
    "        matches = sum(1 for x,y in zip(a,b) if x==y and x!='-' and y!='-')\n",
    "        denom   = sum(1 for x,y in zip(a,b) if not (x=='-' and y=='-'))\n",
    "        ident   = (matches/denom) if denom else 0.0\n",
    "        if (best is None) or (ident > best[\"identity\"]):\n",
    "            best = {\"pred_model\": cls, \"pred_class\": simp, \"identity\": ident, \"score\": score}\n",
    "    if best is None or best[\"identity\"] < MIN_IDENTITY:\n",
    "        return (rec_id, \"NO_HIT\", None, None, None)\n",
    "    return (rec_id, best[\"pred_class\"], best[\"pred_model\"], best[\"identity\"], best[\"score\"])\n",
    "\n",
    "# Stream queries and classify in parallel\n",
    "def records_iter(path):\n",
    "    for r in SeqIO.parse(str(path), \"fasta\"):\n",
    "        yield (r.id.split()[0], str(r.seq))\n",
    "\n",
    "rows = []\n",
    "with mp.Pool(processes=N_PROC) as pool:\n",
    "    for out in pool.imap_unordered(classify_one, records_iter(QUERIES), chunksize=64):\n",
    "        rows.append(out)\n",
    "\n",
    "df_pred = pd.DataFrame(rows, columns=[\"seq_id\",\"pred_class\",\"pred_model\",\"identity\",\"align_score\"])\n",
    "df_pred = df_pred.sort_values(\"seq_id\")\n",
    "out_csv = OUT / \"consensus_identity_predictions_150k.csv\"\n",
    "df_pred.to_csv(out_csv, index=False)\n",
    "print(f\"[OK] wrote {len(df_pred):,} predictions → {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27604909-980a-43d1-93d5-46fe4bb0338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Quick summaries ===\n",
    "\n",
    "pred   = OUT / \"consensus_identity_predictions_150k.csv\"\n",
    "df = pd.read_csv(pred)\n",
    "\n",
    "print(df[\"pred_class\"].value_counts(dropna=False))\n",
    "\n",
    "# identity distribution by class\n",
    "hits = df[df[\"pred_class\"]!=\"NO_HIT\"].copy()\n",
    "plt.figure(figsize=(9,4))\n",
    "for c in sorted(hits[\"pred_class\"].unique()):\n",
    "    x = hits.loc[hits[\"pred_class\"]==c, \"identity\"].values\n",
    "    x.sort()\n",
    "    y = (np.arange(1,len(x)+1)/len(x))*100.0\n",
    "    plt.step(x, y, where=\"post\", label=c)\n",
    "plt.xlabel(\"Global identity to class consensus\")\n",
    "plt.ylabel(\"Percent ≤ identity\")\n",
    "plt.title(\"ECDF of identity by predicted class (consensus-based)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT / \"identity_ecdf_by_class.png\", dpi=150)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d8c33b-bd74-4393-a314-ffbbcf7285b0",
   "metadata": {},
   "source": [
    "Each colored curve shows the ECDF of global percent identity between sequences assigned to that class and that class;s consensus\n",
    "\n",
    "X-axis ==> global identity to class consensus \n",
    "similarity fraction used for assignment; higher = closer match\n",
    "\n",
    "Y-axis  ==> percent of sequences =< that identity\n",
    " steeper a curve rise, the tighter the identity distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a28df5-8a24-4c64-8dc8-4c68c4ab6b89",
   "metadata": {},
   "source": [
    "The consensus-identity method found good matches only for a minority of sequences.\n",
    "\n",
    "most sequences fall below the 30 % global identity threshold which means clustalo consensus alone doesn’t capture diversity\n",
    "\n",
    "Among hits gamma > alpha > beta dominat showing these families are closer to training consensuses\n",
    "\n",
    "The long right tails (up to ~0.6 identity) indicate some very high-confidence matches but most matches cluster around 0.35–0.45."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ab5d79-5617-42cd-b105-8aaec76a9ec4",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47779870-a25c-4fcb-96dc-1ec150ae2375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load Clustal-O based and HMMER based labels for comparison ===\n",
    "\n",
    "# --- Paths ---\n",
    "LABELS_HMMER   = RESULTS / \"uniprot_first_150000_labels_with_confidence.csv\"    #  HMMER based labels\n",
    "LABELS_CLUSTER = OUT / \"consensus_identity_predictions_150k.csv\"               #  Clustal O consensus labels\n",
    "\n",
    "# --- Load ---\n",
    "df_hmm  = pd.read_csv(LABELS_HMMER)\n",
    "df_cons = pd.read_csv(LABELS_CLUSTER)\n",
    "\n",
    "print(f\"[load] HMMER labels: {len(df_hmm):,}  |  ClustalΩ O labels: {len(df_cons):,}\")\n",
    "\n",
    "# Normalize IDs (same format)\n",
    "df_hmm[\"seq_id\"]  = df_hmm[\"seq_id\"].astype(str).str.split().str[0]\n",
    "df_cons[\"seq_id\"] = df_cons[\"seq_id\"].astype(str).str.split().str[0]\n",
    "\n",
    "# Merge on sequence ID\n",
    "df_merged = df_hmm.merge(\n",
    "    df_cons[[\"seq_id\",\"pred_class\"]].rename(columns={\"pred_class\":\"pred_class_consensus\"}),\n",
    "    on=\"seq_id\", how=\"inner\"\n",
    ")\n",
    "print(f\"[merge] {len(df_merged):,} sequences appear in both sets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbf6870-18a7-4e1b-a97a-c2cbaaaa9cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def class_counts(df, label_col, title, out_path):\n",
    "    counts = (df[label_col]\n",
    "              .value_counts(dropna=False)\n",
    "              .rename_axis(\"class\")\n",
    "              .reset_index(name=\"count\")\n",
    "              .sort_values(\"count\", ascending=False))\n",
    "    plt.figure(figsize=(9,5))\n",
    "    plt.bar(counts[\"class\"], counts[\"count\"])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted class\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.show()\n",
    "    return counts\n",
    "\n",
    "counts_hmm  = class_counts(df_hmm,  \"pred_class\", \"HMMER-predicted Classes (150k)\", RESULTS / \"compare_hmmer_dist.png\")\n",
    "counts_cons = class_counts(df_cons, \"pred_class\", \"Consensus-identity Predicted Classes (150k)\", RESULTS / \"compare_consensus_dist.png\")\n",
    "\n",
    "display(counts_hmm)\n",
    "display(counts_cons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fa3596-a22b-438d-8a73-d6ba79f83e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# === Compare overlap and agreement between classification methods ===\n",
    "df_merged[\"agreement\"] = (\n",
    "    df_merged[\"pred_class\"] == df_merged[\"pred_class_consensus\"]\n",
    ")\n",
    "\n",
    "# Overall agreement rate (excluding NO_HIT on either side)\n",
    "mask_valid = (df_merged[\"pred_class\"] != \"NO_HIT\") & (df_merged[\"pred_class_consensus\"] != \"NO_HIT\")\n",
    "agree_rate = df_merged.loc[mask_valid, \"agreement\"].mean()\n",
    "print(f\"[agreement] {agree_rate:.3%} of classified sequences agree between methods \"\n",
    "      f\"(excluding NO_HITs)\")\n",
    "\n",
    "# --- Confusion between methods ---\n",
    "cm = pd.crosstab(df_merged[\"pred_class\"], df_merged[\"pred_class_consensus\"], dropna=False)\n",
    "all_families = sorted(set(df_merged[\"pred_class\"].unique()) | \n",
    "                     set(df_merged[\"pred_class_consensus\"].unique()))\n",
    "cm = cm.reindex(index=all_families, columns=all_families, fill_value=0)\n",
    "print(\"[matrix] HMMER (rows) vs Consensus (columns)\")\n",
    "\n",
    "# Display table\n",
    "display(cm)\n",
    "\n",
    "# === NEW: Colored heatmap visualization ===\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True, fmt=\"d\", cmap=\"viridis\", linewidths=0.5,\n",
    "    cbar_kws={\"label\": \"Count\"}\n",
    ")\n",
    "plt.title(\"HMMER (rows) vs Consensus (columns) Classification Confusion Matrix\")\n",
    "plt.xlabel(\"Consensus-based Class\")\n",
    "plt.ylabel(\"HMMER-predicted Class\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS / \"hmmer_vs_consensus_confusion_heatmap.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# --- Top disagreement examples ---\n",
    "disagree = df_merged[\n",
    "    (df_merged[\"pred_class\"] != df_merged[\"pred_class_consensus\"]) &\n",
    "    (df_merged[\"pred_class\"] != \"NO_HIT\") &\n",
    "    (df_merged[\"pred_class_consensus\"] != \"NO_HIT\")\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e1c7a1-81da-4a7e-ad21-08344ad77fd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# normalize ids\n",
    "df_hmm[\"seq_id\"]  = df_hmm[\"seq_id\"].astype(str).str.split().str[0]\n",
    "df_cons[\"seq_id\"] = df_cons[\"seq_id\"].astype(str).str.split().str[0]\n",
    "\n",
    "# bring over consensus class + identity (+ score if present)\n",
    "cols_to_merge = [\"seq_id\", \"pred_class\"]\n",
    "if \"identity\" in df_cons.columns:\n",
    "    df_cons = df_cons.rename(columns={\"identity\":\"identity_consensus\"})\n",
    "    cols_to_merge.append(\"identity_consensus\")\n",
    "if \"align_score\" in df_cons.columns:\n",
    "    df_cons = df_cons.rename(columns={\"align_score\":\"align_score_consensus\"})\n",
    "    cols_to_merge.append(\"align_score_consensus\")\n",
    "\n",
    "df_merged = df_hmm.merge(df_cons[cols_to_merge], on=\"seq_id\", how=\"inner\") \\\n",
    "                  .rename(columns={\"pred_class_y\":\"pred_class_consensus\",\n",
    "                                   \"pred_class_x\":\"pred_class\"})\n",
    "\n",
    "print(\"[columns] merged has:\", list(df_merged.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e856ed4-be50-400d-839a-958af93916d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.violinplot(\n",
    "    data=df_merged[df_merged[\"pred_class\"]!=\"NO_HIT\"],\n",
    "    x=\"pred_class\", y=\"confidence\", inner=\"quartile\", scale=\"width\"\n",
    ")\n",
    "plt.title(\"Distribution of HMMER confidence per class\")\n",
    "plt.xlabel(\"Predicted class\")\n",
    "plt.ylabel(\"Confidence (−log10 E)\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS / \"conf_per_class_violin.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fcb5cd-a968-453b-847a-f009b442aec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Extract NO_HIT sequences from 150k labeled set and write to FASTA ===\n",
    "\n",
    "# Input files\n",
    "LABELS_CSV = RESULTS / \"uniprot_first_150000_labels_with_confidence.csv\"\n",
    "# Output\n",
    "NO_HIT_FA = RESULTS / \"no_hit_sequences_150k.fasta\"\n",
    "\n",
    "# Load labels and filter for NO_HIT\n",
    "df = pd.read_csv(LABELS_CSV)\n",
    "no_hit_ids = set(df[df[\"pred_class\"] == \"NO_HIT\"][\"seq_id\"].astype(str).str.split().str[0])\n",
    "\n",
    "print(f\"[filter] Found {len(no_hit_ids):,} NO_HIT sequence IDs in labels\")\n",
    "\n",
    "# Extract sequences from original FASTA\n",
    "no_hit_records = []\n",
    "for rec in SeqIO.parse(str(QUERIES_FA), \"fasta\"):\n",
    "    seq_id = rec.id.split()[0]\n",
    "    if seq_id in no_hit_ids:\n",
    "        # Keep original ID and description\n",
    "        no_hit_records.append(rec)\n",
    "\n",
    "print(f\"[extract] Extracted {len(no_hit_records):,} sequences from FASTA\")\n",
    "\n",
    "# Write to output FASTA\n",
    "if no_hit_records:\n",
    "    SeqIO.write(no_hit_records, str(NO_HIT_FA), \"fasta\")\n",
    "    print(f\"[OK] Wrote {len(no_hit_records):,} NO_HIT sequences to: {NO_HIT_FA}\")\n",
    "    \n",
    "    # Quick stats\n",
    "    lengths = [len(r.seq) for r in no_hit_records]\n",
    "    print(f\"[stats] Length range: {min(lengths)}-{max(lengths)} aa\")\n",
    "    print(f\"[stats] Mean length: {sum(lengths)/len(lengths):.1f} aa\")\n",
    "else:\n",
    "    print(\"[warn] No sequences found to write\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8374fa08-e160-4f96-9de1-b141c52d4efd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hmmer_env)",
   "language": "python",
   "name": "hmmer_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
